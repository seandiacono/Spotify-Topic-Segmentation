{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gigaword dataset\n",
    "dev_text = open('data/dev.src.txt', 'r').readlines()\n",
    "test_text = open('data/test.src.txt', 'r').readlines()\n",
    "train_text = open('data/train.src.txt', 'r').readlines()\n",
    "dev_title = open('data/dev.tgt.txt', 'r').readlines()\n",
    "test_title = open('data/test.tgt.txt', 'r').readlines()\n",
    "train_title = open('data/train.tgt.txt', 'r').readlines()\n",
    "\n",
    "# Add all files to single data frame\n",
    "data = pd.DataFrame({'text': train_text + dev_text + test_text, 'title': train_title + dev_title + test_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australia 's current account deficit shrunk by...</td>\n",
       "      <td>australian current account deficit narrows sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at least two people were killed in a suspected...</td>\n",
       "      <td>at least two dead in southern philippines blast\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian shares closed down #.# percent mond...</td>\n",
       "      <td>australian stocks close down #.# percent\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south korea 's nuclear envoy kim sook urged no...</td>\n",
       "      <td>envoy urges north korea to restart nuclear dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south korea on monday announced sweeping tax r...</td>\n",
       "      <td>skorea announces tax cuts to stimulate economy\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  australia 's current account deficit shrunk by...   \n",
       "1  at least two people were killed in a suspected...   \n",
       "2  australian shares closed down #.# percent mond...   \n",
       "3  south korea 's nuclear envoy kim sook urged no...   \n",
       "4  south korea on monday announced sweeping tax r...   \n",
       "\n",
       "                                               title  \n",
       "0  australian current account deficit narrows sha...  \n",
       "1  at least two dead in southern philippines blast\\n  \n",
       "2         australian stocks close down #.# percent\\n  \n",
       "3  envoy urges north korea to restart nuclear dis...  \n",
       "4   skorea announces tax cuts to stimulate economy\\n  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean text from column\n",
    "def clean_text(column):\n",
    "    new_text = []\n",
    "    for row in column:\n",
    "        row = re.sub('<[^>]*>', '', row)\n",
    "        row = re.sub('[^a-zA-Z0-9]', ' ', row)\n",
    "        row = re.sub(' +', ' ', row)\n",
    "        row = row.strip()\n",
    "        row = row.lower()\n",
    "        new_text.append(row)\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = clean_text(data['text'])\n",
    "processed_title = clean_text(data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = ['_START_ '+ str(doc) + ' _END_' for doc in processed_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at least two people were killed in a suspected bomb attack on a passenger bus in the strife torn southern philippines on monday the military said'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_START_ at least two dead in southern philippines blast _END_'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = pd.Series(processed_text)\n",
    "data['clean_title'] = pd.Series(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_count = []\n",
    "summary_count = []\n",
    "\n",
    "for sent in data['clean_text']:\n",
    "    text_count.append(len(sent.split()))\n",
    "    \n",
    "for sent in data['clean_title']:\n",
    "    summary_count.append(len(sent.split()))\n",
    "\n",
    "graph_df = pd.DataFrame() \n",
    "\n",
    "graph_df['text'] = text_count\n",
    "graph_df['summary'] = summary_count\n",
    "\n",
    "graph_df.hist(bins = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = max(text_count)\n",
    "max_summary_len = max(summary_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['clean_text'], data['clean_title'], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text to get the vocab count \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Prepare a tokenizer on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary:  7.831374138629915\n"
     ]
    }
   ],
   "source": [
    "thresh = 5\n",
    "\n",
    "cnt = 0\n",
    "tot_cnt = 0\n",
    "\n",
    "for key, value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt = tot_cnt + 1\n",
    "    if value < thresh:\n",
    "        cnt = cnt + 1\n",
    "    \n",
    "print(\"% of rare words in vocabulary: \", (cnt / tot_cnt) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in X = 90953\n"
     ]
    }
   ],
   "source": [
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "x_tokenizer = Tokenizer(num_words = tot_cnt - cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "x_tr_seq = x_tokenizer.texts_to_sequences(x_train) \n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Pad zero upto maximum length\n",
    "x_tr = pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val = pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "x_voc = x_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 7.390643414692469\n",
      "Size of vocabulary in Y = 54221\n"
     ]
    }
   ],
   "source": [
    "# Prepare a tokenizer on testing data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "thresh = 5\n",
    "\n",
    "cnt = 0\n",
    "tot_cnt = 0\n",
    "\n",
    "for key, value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt = tot_cnt + 1\n",
    "    if value < thresh:\n",
    "        cnt = cnt + 1\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt / tot_cnt) * 100)\n",
    "\n",
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "y_tr_seq = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_test) \n",
    "\n",
    "# Pad zero upto maximum length\n",
    "y_tr = pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "y_voc = y_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, \\\n",
    "    Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 91)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 91, 200)      18190600    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 91, 300),    601200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 91, 300),    721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 200)    10844200    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 91, 300),    721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 54221)  16320521   ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 48,000,121\n",
      "Trainable params: 48,000,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len, ))\n",
    "\n",
    "# Embedding layer\n",
    "enc_emb = Embedding(x_voc, embedding_dim,\n",
    "                    trainable=True)(encoder_inputs)\n",
    "\n",
    "# Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
    "\n",
    "# Encoder LSTM 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using encoder_states as the initial state\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# Embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.4,\n",
    "                    recurrent_dropout=0.2)\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
    "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/time_distributed/dense/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\seand\\AppData\\Local\\Temp\\ipykernel_19316\\2045958862.py\", line 1, in <cell line: 1>\n      history = model.fit(\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 267, in call\n      y = self.layer(inputs, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 219, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model/time_distributed/dense/MatMul'\nOOM when allocating tensor with shape[5632,54221] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/time_distributed/dense/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_14052]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\seand\\OneDrive\\Documents\\University\\Masters\\Thesis\\Spotify-Topic-Segmentation\\text_summarization\\headline_generation.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=1'>2</a>\u001b[0m     [x_tr, y_tr[:, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=2'>3</a>\u001b[0m     y_tr\u001b[39m.\u001b[39;49mreshape(y_tr\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], y_tr\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)[:, \u001b[39m1\u001b[39;49m:],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=4'>5</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[es],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=5'>6</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=6'>7</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m([x_val, y_val[:, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=7'>8</a>\u001b[0m                      y_val\u001b[39m.\u001b[39;49mreshape(y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)[:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=8'>9</a>\u001b[0m                      , \u001b[39m1\u001b[39;49m:]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/seand/OneDrive/Documents/University/Masters/Thesis/Spotify-Topic-Segmentation/text_summarization/headline_generation.ipynb#ch0000021?line=9'>10</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/seand/anaconda3/envs/thesisenv/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/time_distributed/dense/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\seand\\AppData\\Local\\Temp\\ipykernel_19316\\2045958862.py\", line 1, in <cell line: 1>\n      history = model.fit(\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 267, in call\n      y = self.layer(inputs, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\seand\\anaconda3\\envs\\thesisenv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 219, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model/time_distributed/dense/MatMul'\nOOM when allocating tensor with shape[5632,54221] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/time_distributed/dense/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_14052]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_tr, y_tr[:, :-1]],\n",
    "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
    "    epochs=50,\n",
    "    callbacks=[es],\n",
    "    batch_size=128,\n",
    "    validation_data=([x_val, y_val[:, :-1]],\n",
    "                     y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:\n",
    "                     , 1:]),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "991933e55c9ad2a33e133c9a66de8b6c9f625dc5b9c7ac9b8ec31bdc5c541ed9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('thesisenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
